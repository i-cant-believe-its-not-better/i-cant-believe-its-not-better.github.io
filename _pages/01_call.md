---
layout: page
permalink: /cfp/
title: Call for Papers
---

Understanding counter-intuitive results is essential, but under-valued, in an increasingly competitive and fast-paced research environment. This workshop aims to rescue papers with fresh and powerful insights that would otherwise fall into the graveyard of forgotten papers. Such works might be high-hanging fruits in the tree of science, and are often those that need help the most. Benefits from this workshop include:
1. encouraging transparency and rigor in the scientific process
2. sparing time of researchers by documenting failed attempts
3. opening new research directions by identifying unexpected behaviors.

We welcome papers presenting surprising empirical results that do not match a priori intuition nor theoretical expectations, or that highlight failure modes of current approaches. Code sharing is strongly encouraged. Submissions will concentrate on anomalies in:
    + *Data*: idiosyncratic aspects of a dataset that affect the outcome in an unexpected way
    + *Modeling*: simplistic or misspecified model assumptions
    + *Inference*: challenging situations where inference algorithms fail
    + *Validation*: unsatisfactory evaluation metrics.

Two tracks will be considered:

**“I Can’t Believe It’s Not Better!” track**: Papers in this track show unexpected failure modes of new approaches. Although it is preferable that papers explain why the approach performs poorly, this is not essential if the paper demonstrates why the negative result is of interest to the community. Papers in this track should clearly describe the analysis, include a self-critique of the method, and show rigorous results. Authors are encouraged to provide ablation studies to isolate the cause of a method’s performance.

**“Questioning default practices” track**: Papers in this track highlight undesired effects or anomalous behaviors in practices that are widespread or taken for granted in the community. Some examples are questionable performance metrics, historic baseline methods, or datasets that are unsuitable in certain settings. This also includes flawed intuitions or unreasonable assumptions that are commonly made. Ideally, papers should suggest potential fixes or research directions to address such bad practices.

#### How to submit

Submissions to the workshop will be handled through [our OpenReview site](https://openreview.net/group?id=NeurIPS.cc/2020/Workshop/ICBINB).

**Main deadline: October 14 23:59 Anywhere on Earth. Accept/reject notification will be sent out October 31.**

<!--**Late-breaking deadline: June 21 23:59 Anywhere on Earth. Accept/reject notification will be sent out July 1st.**-->

<!-- Camera ready versions will be submitted as markdown files through our [GitHub repository page](https://openreview.net/group?id=NeurIPS.cc/2020/Workshop/ICBINB) for publication online. -->

#### Reviewing criteria

We plan to create an open-minded and diverse space for promising works regardless of the final outcome by providing reviewers with concise guidelines that reward thorough understanding, transparency, and reproducibility rather than high performance. Reviewers will nominate papers with exemplary scientific rigor for publication in PMLR. Papers should clearly convey the interest of the unexpected behavior and demonstrate a high-quality research process.

<!-- We will be selecting for submissions that provide interesting insights on unexpected results. Morevover, we expect all submissions to follow the guidelines of basic courtesy and respect, and to abide by our [code of conduct](https://i-cant-believe-its-not-better.github.io/neurips2020/coc). While there is no page limit, we encourage authors to be concise. -->
We will be selecting for submissions that provide interesting insights on unexpected results. Morevover, we expect all submissions to follow the guidelines of basic courtesy and respect. While there is no page limit, we encourage authors to be concise.

Submissions will be evaluated on the following criteria:

<!-- - Adherence to our [code of conduct](https://i-cant-believe-its-not-better.github.io/neurips2020/coc) -->
- Clarity of writing
- Rigor and transparency in the scientific process
- Vulnerability and honesty in discussion, particularly if the submission is by the original author
- Quality of discussion of limitations
- Significance of new insights
